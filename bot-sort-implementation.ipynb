{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12635633,"sourceType":"datasetVersion","datasetId":7922138},{"sourceId":13957334,"sourceType":"datasetVersion","datasetId":8896695},{"sourceId":695356,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":527360,"modelId":541406},{"sourceId":696513,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":528289,"modelId":542336}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install ultralytics onnxruntime opencv-python pyyaml numpy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport subprocess\n\nprint(\"‚¨áÔ∏è Installing BoT-SORT and dependencies...\")\n# 1. Install helper libraries first to prevent errors\ndeps = [\"filterpy\", \"lapx\", \"yacs\", \"ftfy\", \"regex\", \"loguru\", \"thop\", \"termcolor\", \"scikit-image\", \"gdown\", \"numpy<2.0\"]\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\"] + deps, stdout=subprocess.DEVNULL)\n\n# 2. Install BoxMOT (Pinned version for stability)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"boxmot==10.0.43\", \"--no-deps\"], stdout=subprocess.DEVNULL)\n\nprint(\"‚úÖ Installation Complete. Now run the main code.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport subprocess\n\n# 1. Uninstall the current (broken) numpy\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\"], stdout=subprocess.DEVNULL)\n\n# 2. Install a compatible version (1.26.4 is the safest bet)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\"], stdout=subprocess.DEVNULL)\n\nprint(\"‚úÖ NumPy fixed. Please RESTART your runtime/kernel now.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport onnxruntime as ort\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport torch\nimport os\nimport sys\n\n# ==========================================\n# 1. UNIVERSAL IMPORT (BoT-SORT)\n# ==========================================\nprint(\"üîç Initializing Ultimate BoT-SORT...\")\nBoTSORT_Class = None\n\ndef find_tracker():\n    import importlib\n    paths = [\"boxmot\", \"boxmot.trackers.botsort.botsort\", \"boxmot.trackers.botsort.bot_sort\"]\n    names = [\"BoTSORT\", \"BotSort\", \"BOTSORT\"]\n    for path in paths:\n        try:\n            module = importlib.import_module(path)\n            for name in names:\n                if hasattr(module, name): return getattr(module, name)\n        except ImportError: continue\n    return None\n\nBoTSORT_Class = find_tracker()\nif BoTSORT_Class is None:\n    print(\"‚ùå Error: BoT-SORT not found.\")\n    sys.exit()\n\n# ==========================================\n# 2. BALANCED SETTINGS\n# ==========================================\nCONF_THRESH = 0.30\nASPECT_RATIO_MAX = 0.9    # Vehicle Killer\nMIN_AREA = 2500           # Removes noise\n\n# üö® BALANCED LOGIC (Same as Deep OC-SORT version)\nNECK_ZONE_SIZE = 0.25     # Medium Zone \nMIN_SNATCH_FRAMES = 3     # 0.12s contact\nMAX_SNATCH_FRAMES = 90    # 3.5s limit\n\n# ==========================================\n# 3. INITIALIZE TRACKER\n# ==========================================\nreid_weights = Path('osnet_x1_0_msmt17.pt') # 1. Using the BIG Model\n\ntracker = BoTSORT_Class(\n    model_weights=reid_weights,\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    fp16=False,\n    \n    # 2. BoT-SORT Specific Stability Settings\n    track_high_thresh=0.5,    # Only track clear people\n    new_track_thresh=0.6,     # Hard to start new tracks\n    match_thresh=0.7,         # Strict matching\n    track_buffer=100,         # Remember lost IDs for 4s\n    \n    # 3. The \"Secret Sauce\" of BoT-SORT\n    cmc_method=\"sparseOptFlow\", # Camera Motion Compensation (GMC)\n    appearance_thresh=0.25,     # Trust Re-ID more\n    proximity_thresh=0.55       \n)\n\n# Load Pose & YOLO\nRTMPOSE_PATH = '/kaggle/input/rtm-pose/onnx/default/1/rtmpose-m_ap10k_256.onnx' \nort_sess = ort.InferenceSession(RTMPOSE_PATH, providers=['CPUExecutionProvider'])\nin_name = ort_sess.get_inputs()[0].name\n\ntry:\n    yolo = YOLO('/kaggle/input/best-yolov8m/pytorch/default/1/best _yolov8m.pt')\nexcept:\n    yolo = YOLO('yolo11s.pt')\n\n# ==========================================\n# 4. HELPER FUNCTIONS\n# ==========================================\ndef preprocess_pose(img):\n    resized = cv2.resize(img, (256, 256))\n    mean, std = np.array([123.675, 116.28, 103.53]), np.array([58.395, 57.12, 57.375])\n    return np.expand_dims(((cv2.cvtColor(resized, cv2.COLOR_BGR2RGB) - mean) / std).astype(np.float32).transpose(2, 0, 1), axis=0)\n\ndef get_kpts(outputs, h, w):\n    simcc_x, simcc_y = outputs[0], outputs[1]\n    x = np.argmax(simcc_x, axis=2)[0] / simcc_x.shape[2] * w\n    y = np.argmax(simcc_y, axis=2)[0] / simcc_y.shape[2] * h\n    return np.stack([x, y], axis=-1)\n\n# ==========================================\n# 5. MAIN PIPELINE\n# ==========================================\nVIDEO_PATH = '/kaggle/input/snatching-videos/snatching_videos/snatching_11.mp4'\nOUTPUT_PATH = '/kaggle/working/final_botsort_ultimate.mp4'\n\nif not os.path.exists(VIDEO_PATH):\n    print(\"‚ùå Video missing.\")\n    sys.exit()\n\ncap = cv2.VideoCapture(VIDEO_PATH)\nW, H = int(cap.get(3)), int(cap.get(4))\nFPS = cap.get(cv2.CAP_PROP_FPS) or 25\nout = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'mp4v'), int(FPS), (W, H))\n\ninteraction_timers = {}\npersistence_buffer = {} # Stores \"Grace Frames\"\n\nprint(\"üöÄ Running ULTIMATE BoT-SORT Mode...\")\n\nframe_count = 0\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret: break\n    frame_count += 1\n    if frame_count % 20 == 0: print(f\"Processing frame {frame_count}...\", end='\\r')\n    \n    # 1. DETECT\n    results = yolo.predict(frame, conf=CONF_THRESH, verbose=False, classes=[0])\n    dets_to_track = []\n    \n    for r in results:\n        boxes = r.boxes.xyxy.cpu().numpy()\n        confs = r.boxes.conf.cpu().numpy()\n        clss = r.boxes.cls.cpu().numpy()\n        for box, conf, cls in zip(boxes, confs, clss):\n            x1, y1, x2, y2 = map(int, box[:4])\n            w, h = (x2-x1), (y2-y1)\n            if (w*h) < MIN_AREA: continue\n            if (w / h) > ASPECT_RATIO_MAX: continue\n            dets_to_track.append([x1, y1, x2, y2, conf, cls])\n    \n    dets_to_track = np.array(dets_to_track)\n    \n    # 2. TRACK (BoT-SORT)\n    if len(dets_to_track) > 0:\n        tracks = tracker.update(dets_to_track, frame)\n    else:\n        tracks = np.empty((0, 8))\n        \n    # 3. COLLECT DATA\n    people = []\n    for track in tracks:\n        x1, y1, x2, y2 = map(int, track[:4])\n        tid = int(track[4])\n        \n        # ZONE LOGIC\n        neck_cx = int(x1 + (x2-x1)//2)\n        neck_cy = int(y1 + (y2-y1)*0.15) \n        neck_rad = int((y2-y1)*NECK_ZONE_SIZE)\n        \n        # CHEST LINE (Vertical Filter)\n        chest_y = int(y1 + (y2-y1)*0.40) \n        \n        hands = []\n        crop = frame[max(0,y1):min(H,y2), max(0,x1):min(W,x2)]\n        if crop.size > 0:\n            pose_in = preprocess_pose(crop)\n            kpts = get_kpts(ort_sess.run(None, {in_name: pose_in}), crop.shape[0], crop.shape[1])\n            for k in [9, 10]:\n                if k < len(kpts):\n                    hands.append((int(kpts[k][0]+x1), int(kpts[k][1]+y1)))\n        \n        people.append({'id': tid, 'box': (x1,y1,x2,y2), 'neck': (neck_cx,neck_cy,neck_rad), 'hands': hands, 'chest': chest_y})\n\n    # 4. CROSS-CHECK\n    snatch_alerts = set()\n    \n    for p1 in people: # Thief\n        for p2 in people: # Victim\n            if p1['id'] == p2['id']: continue\n            pair_key = tuple(sorted((p1['id'], p2['id'])))\n            \n            vx, vy, vrad = p2['neck']\n            victim_chest = p2['chest']\n            \n            is_touching = False\n            for hx, hy in p1['hands']:\n                dist = np.sqrt((hx-vx)**2 + (hy-vy)**2)\n                \n                # RULE: Must be CLOSE + ABOVE CHEST\n                if dist < vrad and hy < victim_chest:\n                    is_touching = True\n                    cv2.line(frame, (hx, hy), (vx, vy), (0, 0, 255), 2)\n                    break\n            \n            if is_touching:\n                persistence_buffer[pair_key] = 5 # Reset Buffer\n                \n                if pair_key not in interaction_timers: interaction_timers[pair_key] = 0\n                interaction_timers[pair_key] += 1\n                \n                if interaction_timers[pair_key] >= MIN_SNATCH_FRAMES:\n                    snatch_alerts.add(p1['id'])\n                    snatch_alerts.add(p2['id'])\n            else:\n                # üõ°Ô∏è PERSISTENCE LOGIC\n                if pair_key in persistence_buffer and persistence_buffer[pair_key] > 0:\n                    persistence_buffer[pair_key] -= 1\n                    if interaction_timers.get(pair_key, 0) >= MIN_SNATCH_FRAMES:\n                        snatch_alerts.add(p1['id'])\n                        snatch_alerts.add(p2['id'])\n                else:\n                    if pair_key in interaction_timers:\n                        interaction_timers[pair_key] = max(0, interaction_timers[pair_key] - 1)\n\n    # 5. DRAW\n    for p in people:\n        tid = p['id']\n        x1, y1, x2, y2 = p['box']\n        color = (0, 255, 0)\n        \n        if tid in snatch_alerts:\n            color = (0, 0, 255)\n            cv2.putText(frame, \"SNATCH!\", (x1, y1-30), 0, 1.0, color, 3)\n            nx, ny, nr = p['neck']\n            cv2.circle(frame, (nx, ny), nr, color, 3)\n            \n        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n        cv2.putText(frame, f\"ID:{tid}\", (x1, y1-5), 0, 0.6, (255,255,0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\nprint(f\"‚úÖ DONE: {OUTPUT_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}